# -*- coding: utf-8 -*-
"""Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10j2oBXrKRTZkil_aj-R5JHCK267GPuyU
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

climber_all_clean = pd.read_csv('/content/drive/MyDrive/IA/6to sem/Machine Learning/Proyecto Final/Climbing-Data-Analysis/data/climber_all_clean.csv')
climber_df = pd.read_csv('/content/drive/MyDrive/IA/6to sem/Machine Learning/Proyecto Final/Climbing-Data-Analysis/data/grades.csv')
preprocessed_grades = pd.read_csv('/content/drive/MyDrive/IA/6to sem/Machine Learning/Proyecto Final/Climbing-Data-Analysis/data/climber_df.csv')
print(climber_all_clean.head(10))

print(preprocessed_grades.head(10))

"""##Preprocessing the data"""

# Guardamos grades_max
grades_max = preprocessed_grades['grades_max']
preprocessed_grades = preprocessed_grades.drop('grades_max', axis=1)
# Los quitamos porque no podemos usar tipo de dato string
preprocessed_grades = preprocessed_grades.drop('country', axis=1)
preprocessed_grades = preprocessed_grades.drop('date_first', axis=1)
preprocessed_grades = preprocessed_grades.drop('date_last', axis=1)

# agregamos grades_max de nuevo a los datos pero ahora va a quedar en la ultima columna
preprocessed_grades = pd.concat([preprocessed_grades, grades_max], axis=1)

grades_df = preprocessed_grades

print(grades_df.shape)

grades_df.drop('user_id', axis=1)
print(grades_df.head(5))
X = grades_df.iloc[:, :-1].values
print(X.shape)
Y = grades_df['grades_max'].values

"""##Dimensionality Reduction"""

model_PCA = PCA(n_components=2)
XPCA = model_PCA.fit_transform(X)
print(XPCA.shape)
loadings = model_PCA.components_

#Se reduce la dimensionalidad a 2 componentes, los cuales
#son una combinacion de las caracteristicas originales
# Imprimir las cargas de las características sobre los nuevos PC
for i, componente in enumerate(loadings):
    print(f"Cargas del Componente Principal {i+1}:")
    for j, carga in enumerate(componente):
        print(f"Característica {j+1}: {carga}")

plt.figure(figsize=(10, 5))
plt.plot(np.arange(XPCA.shape[1]), np.cumsum(model_PCA.explained_variance_ratio_))
plt.grid(linestyle='-', linewidth=1)
plt.show()

print(grades_df.head(5))

model = PCA()
X2 = model.fit_transform(X)
print(X2.shape)

plt.figure(figsize=(10,5))
plt.plot( np.arange(X.shape[1]), np.cumsum(model.explained_variance_ratio_))
plt.grid(linestyle='-',linewidth=1)
plt.show()

varexp = np.round(model.explained_variance_ratio_)
cvarexp = np.round(np.cumsum(model.explained_variance_ratio_), 2)
print(varexp) # LA varianza de cada variable
print(cvarexp) # La varianza acumulada, para ver hasta que variable nos conviene tomar.

"""##Training and evaluating the model"""

#X = np.concatenate((XPCA, XPCA**2), axis=1)

Xtrain, Xtest, ytrain, Ytest = train_test_split(X, Y, test_size=0.30, random_state=0)

"""#Comparación de diferentes modelos de Regression"""

Regressors = [
    SVC(),
    RandomForestRegressor(),
    MLPRegressor(),
    KNeighborsRegressor(),
    LinearRegression()
]
regressorsNames = [
    "SVC",
    "RandomForestRegressor",
    "MLPRegressor",
    "KNeighborsRegressor",
    "LinearRegression"
]
r2_scores = []
predicts = []

i = 0
for model in Regressors:
  model.fit(Xtrain, ytrain)
  y_pred = model.predict(Xtest)
  predicts.append(y_pred)
  mae = mean_absolute_error(Ytest, y_pred)
  mse = mean_squared_error(Ytest, y_pred)
  r2 = r2_score(Ytest, y_pred)
  r2_scores.append(r2)

  print(f"mae: {mae:.2f}")
  print(f"mse: {mse:.2f}")
  print(f"R2: {r2:.2f}")
  # plot the scatter plot
  plt.scatter(Ytest, y_pred)
  plt.xlabel("Real Testing Target Values")
  plt.ylabel("Predicting Values")
  plt.title(regressorsNames[i])
  plt.show()
  i += 1

"""#Mostrar estadísticas de escaladores.

El país que tiene mayores grados escalados, sumatoria.

Relación peso - altura.

Relación cuantos son mujeres y cuantos hombres.

Distribución de los grados escalados.

#Distribución de grados en el dataset.
"""

distribucion_grados = climber_all_clean['max_fra'].value_counts().sort_index()

# Configurar la figura y los ejes
fig, ax = plt.subplots(figsize=(10, 6))

# Graficar la distribución de los grados
distribucion_grados.plot(kind='bar', ax=ax)

ax.set_xlabel('Grado')
ax.set_ylabel('Número de escaladores')
ax.set_title('Distribución de los grados escalados por los escaladores')

plt.xticks(rotation='vertical')
plt.show()

escaladores_mex = climber_all_clean.loc[climber_all_clean['country'] == 'MEX']
print(escaladores_mex)

"""Grados máximos por pais

"""

orden_grados = ['8c/+', '9a', '9a/+', '9b', '9b/+', '9b+']

# Filtrar los escaladores únicos de cada país con su grado máximo y establecer el orden de los grados máximos
escaladores_pais_max = climber_all_clean.groupby('country')['max_fra'].max().reset_index()
escaladores_pais_max['max_fra'] = pd.Categorical(escaladores_pais_max['max_fra'], ordered=True)
escaladores_pais_max = escaladores_pais_max.sort_values('max_fra')

# Filtrar y ordenar la cantidad de escaladores por grado máximo
escaladores_pais_max_count = climber_all_clean.groupby(['country', 'max_fra']).size().reset_index(name='count')
escaladores_pais_max_count['max_fra'] = pd.Categorical(escaladores_pais_max_count['max_fra'], categories=orden_grados, ordered=True)
escaladores_pais_max_count = escaladores_pais_max_count.sort_values('max_fra')

# Configurar la figura y los ejes
fig, ax = plt.subplots(figsize=(10, 6))

# Graficar los grados máximos
ax.bar(escaladores_pais_max['country'], escaladores_pais_max['max_fra'], label='Grado máximo')

# Etiquetas y título
ax.set_xlabel('País')
ax.set_ylabel('Grado máximo')
ax.set_title('Grado máximo escalado por los escaladores de cada país')

# Mostrar la cantidad de escaladores por grado máximo
for i, row in escaladores_pais_max_count.iterrows():
    country = row['country']
    max_fra = row['max_fra']
    count = row['count']
    #ax.annotate(text=str(count), xy=(country, max_fra), xytext=(0, 5), textcoords='offset points', ha='center', va='bottom')

# Ajustar las etiquetas del eje x en caso de muchos países
plt.xticks(rotation='vertical')

# Mostrar la leyenda y ajustar el diseño
ax.legend()
plt.tight_layout()

# Mostrar la gráfica
plt.show()

"""Relación peso altura y grado máximo."""

data = climber_all_clean[['height', 'weight', 'grades_max']]
grades_mean = grades_df['grades_mean']

# Configurar la figura y los ejes
fig, ax = plt.subplots(figsize=(10, 6))

# Graficar la relación entre el peso, la altura y el grado máximo
scatter = ax.scatter(data['weight'], data['height'], c=data['grades_max'], cmap='coolwarm')

cbar = plt.colorbar(scatter) # Añadir una barra de color para el grado máximo
cbar.set_label('Grado máximo')

ax.set_xlabel('Peso')
ax.set_ylabel('Altura')
ax.set_title('Relación entre peso, altura y grado máximo')
plt.show()

conversion_df = pd.read_csv('/content/drive/MyDrive/IA/6to sem/Machine Learning/Proyecto Final/Archives/grades_conversion_table.csv')

data = climber_all_clean[['sex', 'grades_max']]
grades_mean = grades_df['grades_mean']

# Agrupar los datos por género y grado máximo y contar la cantidad de escaladores
grouped_data = data.groupby(['sex', 'grades_max']).size().unstack()

# Configurar la figura y los ejes
fig, ax = plt.subplots(figsize=(10, 6))

# Graficar los datos
grouped_data.plot(kind='bar', ax=ax)

# Etiquetas y título
ax.set_xlabel('Grado máximo')
ax.set_ylabel('Cantidad de escaladores')
ax.set_title('Relación entre género y grado máximo')

# Mostrar la gráfica
plt.show()

print(conversion_df)

# Función para buscar una persona por su ID y hacer una predicción
def predecir_grades_max(user_id):
    persona = preprocessed_grades[preprocessed_grades['user_id'] == user_id]
    if persona.empty:
        print(f"No se encontró la persona con ID {user_id}.")
    else:
        #X_persona = persona[features]
        persona.drop('user_id', axis=1)
        prediccion = Regressors[1].predict(persona)
        print(f"Predicción de grades_max para la persona con ID {user_id}: {prediccion[0]}")

# Ejemplo de uso: buscar a la persona con ID 4 y hacer una predicción
predecir_grades_max(4)

gradeslast = pd.read_csv('/content/drive/MyDrive/IA/6to sem/Machine Learning/Proyecto Final/Climbing-Data-Analysis/data/climber_df.csv')
print(gradeslast.head(5))
print(gradeslast['user_id'])
persona = gradeslast[gradeslast['user_id'] == user_id]

print(persona)